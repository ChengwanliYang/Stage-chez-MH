{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd28e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import dataiku\n",
    "import pandas as pd, numpy as np\n",
    "from dataiku import pandasutils as pdu\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS as stop_sp\n",
    "\n",
    "# Read recipe inputs\n",
    "token_insatis = dataiku.Dataset(\"token_insatis\")\n",
    "token_insatis_df = token_insatis.get_dataframe()\n",
    "\n",
    "\n",
    "# Compute recipe outputs from inputs\n",
    "# TODO: Replace this part by your actual code that computes the output, as a Pandas dataframe\n",
    "# NB: DSS also supports other kinds of APIs for reading and writing data. Please see doc.\n",
    "\n",
    "#token_insatis_supp_mot_vide_df = token_insatis_df # For this sample code, simply copy input to output\n",
    "\n",
    "\n",
    "# Write recipe outputs\n",
    "#token_insatis_supp_mot_vide = dataiku.Dataset(\"token_insatis_supp_mot_vide\")\n",
    "#token_insatis_supp_mot_vide.write_with_schema(token_insatis_supp_mot_vide_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae01758",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_nltk = list(stopwords.words('french'))\n",
    "liste_stop_sp = list(stop_sp)\n",
    "liste_stop_sp.append(\"euh\")\n",
    "liste_stop_sp.append(\"ben\")\n",
    "liste_stop_sp.append(\"hein\")\n",
    "liste_stop_sp.append(\"hum\")\n",
    "liste_stop_sp.append(\"hop\")\n",
    "liste_stop = set(stop_nltk+liste_stop_sp)\n",
    "#print(liste_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1ea51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = token_insatis_df['token']\n",
    "liste_token = list(token)\n",
    "#print(len(liste_token))\n",
    "liste_token_net = [word for word in liste_token if word not in liste_stop]\n",
    "#print(len(liste_token_net))\n",
    "for mot in liste_token_net :\n",
    "    \n",
    "    liste_token_net.count(mot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28ad110",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_id = list(token_insatis_df['nom'])\n",
    "liste_token = list(token_insatis_df['token'])\n",
    "liste_id_set = set(liste_id)\n",
    "for i in range(len(liste_id_set)):\n",
    "    nom = liste_id_set[i]\n",
    "    freq = liste_id.count(i)\n",
    "    print(nom,freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3084099f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
