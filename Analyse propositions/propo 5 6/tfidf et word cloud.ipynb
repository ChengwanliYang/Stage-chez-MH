{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df05f05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------- NOTEBOOK-CELL: CODE\n",
    "# -*- coding: utf-8 -*-\n",
    "import dataiku\n",
    "import pandas as pd, numpy as np\n",
    "from dataiku import pandasutils as pdu\n",
    "\n",
    "# Read recipe inputs\n",
    "commentaire_negatif_att_set_hubiscus = dataiku.Dataset(\"commentaire_negatif_att_set_hubiscus\")\n",
    "commentaire_negatif_att_set_hubiscus_df = commentaire_negatif_att_set_hubiscus.get_dataframe()\n",
    "\n",
    "liste_commentaire = list(commentaire_negatif_att_set_hubiscus_df['commentaire'])\n",
    "liste_nom = list(commentaire_negatif_att_set_hubiscus_df['nom'])\n",
    "\n",
    "# Compute recipe outputs from inputs\n",
    "# TODO: Replace this part by your actual code that computes the output, as a Pandas dataframe\n",
    "# NB: DSS also supports other kinds of APIs for reading and writing data. Please see doc.\n",
    "\n",
    "#commentaire_negatif_tf_df = commentaire_negatif_att_set_hubiscus_df # For this sample code, simply copy input to output\n",
    "\n",
    "\n",
    "# Write recipe outputs\n",
    "#commentaire_negatif_tf = dataiku.Dataset(\"commentaire_negatif_tf\")\n",
    "#commentaire_negatif_tf.write_with_schema(commentaire_negatif_tf_df)\n",
    "\n",
    "# -------------------------------------------------------------------------------- NOTEBOOK-CELL: CODE\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.feature_extraction.text import TfidfTransformer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS as fr_stop\n",
    "\n",
    "# -------------------------------------------------------------------------------- NOTEBOOK-CELL: MARKDOWN\n",
    "# *wordcloud*\n",
    "\n",
    "# -------------------------------------------------------------------------------- NOTEBOOK-CELL: CODE\n",
    "# pour wordcloud\n",
    "final_stopwords_list = list(fr_stop)\n",
    "vectorizer = TfidfVectorizer(stop_words=final_stopwords_list) #stop_words=final_stopwords_list\n",
    "transformer=TfidfTransformer()\n",
    "tfidf=transformer.fit_transform(vectorizer.fit_transform(liste_commentaire))\n",
    "word=vectorizer.get_feature_names()\n",
    "weight=tfidf.toarray()\n",
    "\n",
    "liste_dic_all = []\n",
    "for i in range(len(weight)):#打印每类文本的tf-idf词语权重，第一个for遍历所有文本，第二个for便利某一类文本下的词语权重  \n",
    "        #print (u\"-------这里输出第\",i,u\"类文本的词语tf-idf权重------\" ) \n",
    "        liste_dic = []\n",
    "        dic = {}\n",
    "        for j in range(len(word)):  \n",
    "           \n",
    "            #dic.update(word[j]:weight[i][j])\n",
    "            dic[word[j]] = weight[i][j]\n",
    "        liste_dic.append(dic)\n",
    "        liste_dic_all.append(liste_dic)\n",
    "\n",
    "# -------------------------------------------------------------------------------- NOTEBOOK-CELL: CODE\n",
    "l =[] #tous les mots\n",
    "for i in range(len(liste_dic_all)):\n",
    "#liste_1 = liste_dic_all[5]\n",
    "    for i in liste_dic_all[i]:\n",
    "        for key,value in i.items():\n",
    "            if(value > 0):\n",
    "           # if 'attend' in key:\n",
    "                #print (key,value)\n",
    "                l.append(key)\n",
    "print(len(l))\n",
    "\n",
    "# -------------------------------------------------------------------------------- NOTEBOOK-CELL: MARKDOWN\n",
    "# *mots 4 gram*\n",
    "\n",
    "# -------------------------------------------------------------------------------- NOTEBOOK-CELL: CODE\n",
    "# pour des mots 4 gram\n",
    "final_stopwords_list = list(fr_stop)\n",
    "vectorizer = TfidfVectorizer(ngram_range=(4,4)) #stop_words=final_stopwords_list\n",
    "transformer=TfidfTransformer()\n",
    "tfidf=transformer.fit_transform(vectorizer.fit_transform(liste_commentaire))\n",
    "word=vectorizer.get_feature_names()\n",
    "weight=tfidf.toarray()\n",
    "\n",
    "liste_dic_all = []\n",
    "for i in range(len(weight)):  \n",
    "       \n",
    "        liste_dic = []\n",
    "        dic = {}\n",
    "        for j in range(len(word)):  \n",
    "           \n",
    "            #dic.update(word[j]:weight[i][j])\n",
    "            dic[word[j]] = weight[i][j]\n",
    "        liste_dic.append(dic)\n",
    "        liste_dic_all.append(liste_dic)\n",
    "            #print(dic)\n",
    "            #print(word[j],weight[i][j])  \n",
    "#print(liste_dic_all[0])\n",
    "\n",
    "# -------------------------------------------------------------------------------- NOTEBOOK-CELL: CODE\n",
    "l_word =[] \n",
    "for f in range(len(liste_nom)):\n",
    "    for i in liste_dic_all[f]:\n",
    "        dic = {}\n",
    "        dic['nom'] = str(liste_nom[f])\n",
    "        l=[]\n",
    "        for key,value in i.items():\n",
    "            \n",
    "            if(value == max(i.values())):\n",
    "                l.append(key)\n",
    "        dic['tfidf_mot'] = l\n",
    "        l_word.append(dic)\n",
    "print(l_word[0])\n",
    "\n",
    "# -------------------------------------------------------------------------------- NOTEBOOK-CELL: CODE\n",
    "new_df = pd.DataFrame(l_word)\n",
    "commentaire_negatif_tf = dataiku.Dataset(\"commentaire_negatif_tf\")\n",
    "commentaire_negatif_tf.write_with_schema(new_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
